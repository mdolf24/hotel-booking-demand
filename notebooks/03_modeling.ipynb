{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01317ff9",
   "metadata": {},
   "source": [
    "# 0) Setup and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e804034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119390, 32),\n",
       " Index(['hotel', 'is_canceled', 'lead_time', 'arrival_date_year',\n",
       "        'arrival_date_month', 'arrival_date_week_number',\n",
       "        'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
       "        'stays_in_week_nights', 'adults'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "DATA_PATH = os.path.join(\"..\", \"data\", \"hotel_bookings.csv\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.shape, df.columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b079a3",
   "metadata": {},
   "source": [
    "# 1) Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c5c8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119390, 8), (119390,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = df.copy()\n",
    "\n",
    "#basic target\n",
    "y = df_model[\"is_canceled\"].astype(float)\n",
    "\n",
    "#simple, stable features (mostly numeric)\n",
    "df_model[\"total_guests\"] = (\n",
    "    df_model.get(\"adults\", 0).fillna(0)\n",
    "    + df_model.get(\"children\", 0).fillna(0)\n",
    "    + df_model.get(\"babies\", 0).fillna(0)\n",
    ")\n",
    "\n",
    "#binary encode hotel type (City=1, Resort=0)\n",
    "df_model[\"hotel_city\"] = (df_model[\"hotel\"] == \"City Hotel\").astype(int)\n",
    "feature_cols = [\n",
    "    \"lead_time\",\n",
    "    \"adr\",\n",
    "    \"stays_in_week_nights\",\n",
    "    \"stays_in_weekend_nights\",\n",
    "    \"total_guests\",\n",
    "    \"hotel_city\",\n",
    "    \"previous_cancellations\",\n",
    "    \"booking_changes\"\n",
    "]\n",
    "\n",
    "X_df = df_model[feature_cols].copy()\n",
    "\n",
    "#quickly hande missing values\n",
    "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
    "mask = X_df.notna().all(axis=1) & y.notna()\n",
    "\n",
    "X = X_df.loc[mask].to_numpy(dtype=float)\n",
    "y = y.loc[mask].to_numpy(dtype=float)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110214ef",
   "metadata": {},
   "source": [
    "# 2) Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8a90aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (95512, 8) (95512,)\n",
      "Test shapes: (23878, 8) (23878,)\n",
      "Design shapes: (95512, 9) (23878, 9)\n",
      "First row (train): [ 1.         -0.76832031  0.72694085  0.26633103  0.07679599  0.04223071\n",
      "  0.70918444 -0.10225844 -0.33922077]\n"
     ]
    }
   ],
   "source": [
    "#1) reproducible shuffle\n",
    "rng = np.random.default_rng(42)\n",
    "n = X.shape[0]\n",
    "idx = rng.permutation(n)\n",
    "\n",
    "#2) train/test split (80/20)\n",
    "split = int(0.8 * n)\n",
    "train_idx = idx[:split]\n",
    "test_idx = idx[split:]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "print(\"Train shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shapes:\", X_test.shape, y_test.shape)\n",
    "\n",
    "#3) z-score standardization\n",
    "mu = X_train.mean(axis=0)\n",
    "sigma = X_train.std(axis=0)\n",
    "sigma[sigma == 0] = 1.0\n",
    "\n",
    "X_train_s = (X_train - mu) / sigma\n",
    "X_test_s = (X_test - mu) / sigma\n",
    "\n",
    "#4) intercept (design matrix)\n",
    "X_train_design = np.column_stack([np.ones(X_train_s.shape[0]), X_train_s])\n",
    "X_test_design = np.column_stack([np.ones(X_test_s.shape[0]), X_test_s])\n",
    "\n",
    "print(\"Design shapes:\", X_train_design.shape, X_test_design.shape)\n",
    "print(\"First row (train):\", X_train_design[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94cfb57",
   "metadata": {},
   "source": [
    "# 3) Fit a NumPy Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de56f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta shape: (9,)\n",
      "First 5 train predictions: [0.34251092 0.31006186 0.15642004 0.44584317 0.09932604]\n",
      "First 5 test predictions:  [0.33954775 0.83666817 0.52176555 0.17107856 0.60683405]\n",
      "Test predictions clipped range: 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "#fit model using least squares: minimize squared errors\n",
    "beta, residuals, ran, s = np.linalg.lstsq(X_train_design, y_train, rcond=None)\n",
    "\n",
    "#predictions on train and test\n",
    "y_pred_train = X_train_design @ beta\n",
    "y_pred_test = X_test_design @ beta\n",
    "\n",
    "#quick sanity checks (first 5 predictions)\n",
    "print(\"beta shape:\", beta.shape)\n",
    "print(\"First 5 train predictions:\", y_pred_train[:5])\n",
    "print(\"First 5 test predictions: \", y_pred_test[:5])\n",
    "\n",
    "#clip predictions to [0,1] for interpretability\n",
    "y_pred_test_clipped = np.clip(y_pred_test, 0, 1)\n",
    "print(\"Test predictions clipped range:\", y_pred_test_clipped.min(), y_pred_test_clipped.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ae6f05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance:\n",
      "Train MSE: 0.2030\n",
      "Test  MSE: 0.2038\n",
      "Train R²:  0.1297\n",
      "Test  R²:  0.1261\n",
      "\n",
      "Baseline performance:\n",
      "Baseline Train MSE: 0.2332\n",
      "Baseline Test  MSE: 0.2332\n"
     ]
    }
   ],
   "source": [
    "#evaluation metrics\n",
    "def mse(y_true, y_pred):                \n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r2(y_true, y_pred):             #how much of the variance is explained by the model\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - ss_res / ss_tot if ss_tot != 0 else np.nan\n",
    "\n",
    "#model performance\n",
    "train_mse = mse(y_train, y_pred_train)          #how the model adapts to training data\n",
    "test_mse = mse(y_test, y_pred_test)             #how good the model generalizes\n",
    "\n",
    "train_r2 = r2(y_train, y_pred_train)\n",
    "test_r2 = r2(y_test, y_pred_test)\n",
    "\n",
    "print(\"Model performance:\")\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Test  MSE: {test_mse:.4f}\")\n",
    "print(f\"Train R²:  {train_r2:.4f}\")\n",
    "print(f\"Test  R²:  {test_r2:.4f}\")\n",
    "\n",
    "#baseline model\n",
    "baseline_pred_train = np.full_like(y_train, y_train.mean())             #use a naive model, always predicts the same value\n",
    "baseline_pred_test = np.full_like(y_test, y_train.mean())\n",
    "\n",
    "baseline_train_mse = mse(y_train, baseline_pred_train)              #check how good is the model compared to baseline\n",
    "baseline_test_mse = mse(y_test, baseline_pred_test)\n",
    "\n",
    "\n",
    "print(\"\\nBaseline performance:\")\n",
    "print(f\"Baseline Train MSE: {baseline_train_mse:.4f}\")\n",
    "print(f\"Baseline Test  MSE: {baseline_test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5d9e0",
   "metadata": {},
   "source": [
    "**Linear Probability Model Interpretation**\n",
    "\n",
    "The linear probability model serves as a simple and interpretable baseline for analyzing cancellation behavior. It outperforms a naive mean-based baseline, indicating that booking characteristics contain useful predictive information, although overall predictive performance remains limited due to the binary nature of the target. Consequently, the model is primarily valuable for understanding the direction and relative importance of key features rather than for accurate individual-level prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b14bc",
   "metadata": {},
   "source": [
    "# 4) Logistic Regression for Cancellation Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eaadde",
   "metadata": {},
   "source": [
    "To complement the linear probability model, we fit a logistic regression model to predict booking cancellations. Logistic regression is more appropriate for binary outcomes, as it directly models probabilities in the [0,1] interval and often provides improved predictive performance. The goal of this section is to assess whether a more flexible model can outperform the linear model in terms of prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a7c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance (Test set):\n",
      "Accuracy: 0.700\n",
      "AUC:      0.632\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.90      0.79     15036\n",
      "         1.0       0.67      0.37      0.48      8842\n",
      "\n",
      "    accuracy                           0.70     23878\n",
      "   macro avg       0.69      0.63      0.63     23878\n",
      "weighted avg       0.69      0.70      0.67     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit logistic regression\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_s, y_train)                  #learn connection between features and cancellation probability using sigmoid function\n",
    "\n",
    "#Predictions\n",
    "y_pred_test_lr = logreg.predict(X_test_s)               #retuns class probabilities (0 or 1)\n",
    "y_prob_test_lr = logreg.predict_proba(X_test_s)[:, 1]       #returns predicted cancellation probabilities\n",
    "\n",
    "#Evaluation metrics\n",
    "acc = accuracy_score(y_test, y_pred_test_lr)\n",
    "auc = roc_auc_score(y_test, y_pred_test_lr)             #how good does the model separate between cancelled and not-cancelled bookings\n",
    "\n",
    "print(\"Logistic Regression Performance (Test set):\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"AUC:      {auc:.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab01e2c",
   "metadata": {},
   "source": [
    "**Logistic Regression Results Interpretation**\n",
    "\n",
    "The logistic regression model achieves a test accuracy of 0.70 and an AUC of 0.632, indicating moderate predictive performance. The model correctly identifies most non-canceled bookings, but has lower recall for canceled bookings, reflecting the inherent difficulty of predicting cancellations. Overall, logistic regression provides improved and more realistic predictions compared to the linear probability model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0206c6",
   "metadata": {},
   "source": [
    "# 5) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35edaca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance (Test set):\n",
      "Accuracy: 0.770\n",
      "AUC:      0.711\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.94      0.84     15036\n",
      "         1.0       0.82      0.48      0.61      8842\n",
      "\n",
      "    accuracy                           0.77     23878\n",
      "   macro avg       0.79      0.71      0.72     23878\n",
      "weighted avg       0.78      0.77      0.75     23878\n",
      "\n",
      "\n",
      "Top feature importances:\n",
      "lead_time                  0.385237\n",
      "previous_cancellations     0.187952\n",
      "adr                        0.185512\n",
      "booking_changes            0.099256\n",
      "stays_in_week_nights       0.048424\n",
      "hotel_city                 0.034591\n",
      "total_guests               0.032751\n",
      "stays_in_weekend_nights    0.026277\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Fit Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,                       #number of trees\n",
    "    max_depth=15,                           #decreases overfitting\n",
    "    min_samples_leaf=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_s, y_train)                \n",
    "\n",
    "#Predictions\n",
    "y_pred_test_rf = rf.predict(X_test_s)              \n",
    "y_prob_test_rf = rf.predict_proba(X_test_s)[:, 1]       \n",
    "\n",
    "#Evaluation\n",
    "acc_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_pred_test_rf)              \n",
    "\n",
    "print(\"Random Forest Performance (Test set):\")\n",
    "print(f\"Accuracy: {acc_rf:.3f}\")\n",
    "print(f\"AUC:      {auc_rf:.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test_rf))\n",
    "\n",
    "# 4) Feature importances\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=False)           #how much every variable affects decrease in impurity\n",
    "print(\"\\nTop feature importances:\")\n",
    "print(importances.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41a20d",
   "metadata": {},
   "source": [
    "The random forest model achieves the strongest predictive performance and improves recall for canceled bookings. Feature importance analysis consistently identifies lead time, previous cancellations, and ADR as the most important drivers of cancellations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "285506be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 0.7832574361681253),\n",
       " (10, 0.7963537927431528),\n",
       " (12, 0.8097957723600131),\n",
       " (15, 0.8252420083377967)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuning of max depth parameter\n",
    "results = []\n",
    "\n",
    "for depth in [8, 10, 12, 15]:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=depth,\n",
    "        min_samples_leaf=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train_s, y_train)\n",
    "    y_prob = rf.predict_proba(X_test_s)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    results.append((depth, auc))\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf056a",
   "metadata": {},
   "source": [
    "A limited hyperparameter search over the maximum tree depth shows a consistent improvement in AUC as model complexity increases. The random forest with max_depth = 15 achieves the best performance, indicating that non-linear effects and feature interactions play an important role in cancellation prediction. No clear signs of overfitting are observed within the tested range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf4013",
   "metadata": {},
   "source": [
    "# 6) Model evaluation and baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Linear Probability Model (NumPy)\",\n",
    "        \"Logistic Regression\",\n",
    "        \"Random Forest (tuned)\"\n",
    "    ],\n",
    "    \"Metrics\": [\n",
    "        \"Test MSE = 0.2038, Test R² = 0.1261\",     # <-- replace if you recomputed\n",
    "        \"Test Accuracy = 0.700, Test AUC = 0.632\", # <-- your output\n",
    "        \"Test Accuracy = 0.770, Test AUC = 0.711\"  # <-- your tuned RF output\n",
    "    ],\n",
    "    \"Best For\": [\n",
    "        \"Interpretability (direction of effects)\",\n",
    "        \"Simple prediction + probability estimates\",\n",
    "        \"Best predictive performance\"\n",
    "    ],\n",
    "    \"Key Notes\": [\n",
    "        \"Outperforms baseline MSE (mean predictor)\",\n",
    "        \"Struggles to recall cancellations (class 1)\",\n",
    "        \"Improves recall for cancellations + captures non-linearity\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
